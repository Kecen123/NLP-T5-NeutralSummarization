{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06d3b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/eacv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "import re\n",
    "from bleu import multi_list_bleu, list_bleu\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaf07b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, join_again=True):\n",
    "    text = text.replace(\"U.S.\", \"USA\")\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(w) for w in word_tokenize(text)]\n",
    "    \n",
    "    if join_again:\n",
    "        text = \" \".join(tokens)\n",
    "        return text\n",
    "    else:\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caa95969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_VAD_lexicons():\n",
    "    VAD_path = 'data/lexicons/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt'\n",
    "    with open(VAD_path, 'r') as infile:\n",
    "        lines = infile.read()\n",
    "        lines = lines.split(\"\\n\")\n",
    "        \n",
    "        vad_dict = {}\n",
    "        \n",
    "        for l in lines:            \n",
    "            lexicon, v_score, a_score, d_score = l.split(\"\\t\")\n",
    "\n",
    "            vad_dict[lexicon] = {\n",
    "                'v': float(v_score),\n",
    "                'a': float(a_score),\n",
    "                'd': float(d_score)\n",
    "            }\n",
    "        \n",
    "        return vad_dict\n",
    "    \n",
    "vad_dict = load_VAD_lexicons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98054145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86632b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def obtain_instance_bias_scores(instance_tokens, vad_dict):\n",
    "    exists_vad_token_cnt = 0\n",
    "    v_score = 0\n",
    "    v_positive = 0\n",
    "    v_negative = 0\n",
    "    \n",
    "    p_arousal, n_arousal, m_arousal = 0,0,0\n",
    "    positive, mid, negative = [], [], []\n",
    "\n",
    "    for t in instance_tokens:\n",
    "        if t in vad_dict:\n",
    "            exists_vad_token_cnt+=1\n",
    "            v_score += vad_dict[t]['v']\n",
    "            \n",
    "            if vad_dict[t]['v'] < 0.5:\n",
    "                v_negative += abs(vad_dict[t]['v'] - 0.5)\n",
    "            else:\n",
    "                v_positive += abs(vad_dict[t]['v'] - 0.5 )\n",
    "            \n",
    "            if vad_dict[t]['v'] > 0.65: # positive\n",
    "                positive.append(t)\n",
    "                p_arousal += vad_dict[t]['a']\n",
    "            elif vad_dict[t]['v'] < 0.35: # negative\n",
    "                negative.append(t)\n",
    "                n_arousal += vad_dict[t]['a']\n",
    "            else:\n",
    "                mid.append(t)\n",
    "                m_arousal += vad_dict[t]['a']\n",
    "    \n",
    "\n",
    "    return v_score, v_positive, v_negative, exists_vad_token_cnt, (p_arousal, n_arousal, m_arousal), (positive, negative, mid)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bd832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6ac4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5279d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gens = open(\"/home/eacv/kevinyao/nlp/framing-bias-metric/naacl2022/bart-large.article_ft.3e-5.512_250.e10/base5.txt\", \"r\").readlines()\n",
    "# gens = open(\"/home/eacv/kevinyao/nlp/framing-bias-metric/data/naacl2022_lrc_roundup_random_order_probe/test-center.source\", \"r\").readlines()\n",
    "# load your generations here\n",
    "test_tgts = open(\"/home/eacv/kevinyao/nlp/framing-bias-metric/data/naacl2022_lrc_roundup_random_order_probe/test.target\",\"r\").readlines()\n",
    "# load your gold target texts here\n",
    "test_srcs = open(\"/home/eacv/kevinyao/nlp/framing-bias-metric/data/naacl2022_lrc_roundup_random_order_probe/test.source\",\"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83ba23b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n",
      "1071\n",
      "[Info] Starting to run this command now: perl /tmp/tmp_bleu/multi-bleu-detok.perl /tmp/tmp_bleu/ref_dtk0.txt < /tmp/tmp_bleu/hyp_dtk0.txt \n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "[ROUGE 1] {'r': 0.32320838582218653, 'p': 0.3729032660099502, 'f': 0.3287226366765919}\n",
      "[ROUGE 2] {'r': 0.10563895459060559, 'p': 0.12185246106963125, 'f': 0.10645402216545072}\n",
      "[ROUGE L] {'r': 0.2940791912471245, 'p': 0.33988458573546415, 'f': 0.2992518140010938}\n",
      "[BLEU] 10.88\n",
      "[v]: 8986.81 | 8.39\n",
      "[v_positive]: 1972.84 | 1.84\n",
      "[v_negative]: 792.03 | 0.74\n",
      "[calibrated_p_arousal]: 2823.79 | 2.64\n",
      "[calibrated_n_arousal]: 1432.13 | 1.34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Bias calculation WITH calibration - \"TEST data\"\n",
    "'''\n",
    "\n",
    "print(len(gens))\n",
    "print(len(test_tgts))\n",
    "\n",
    "assert len(gens) == len(test_tgts)\n",
    "cnt = len(gens)\n",
    "test_gen_score_dict = defaultdict(float)\n",
    "\n",
    "# calculate ROUGE\n",
    "results = rouge.get_scores(gens, test_tgts, avg=True)\n",
    "blue_score = list_bleu(test_tgts, gens)\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "# print(pred_path)\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"[ROUGE 1]\", results['rouge-1'])\n",
    "print(\"[ROUGE 2]\", results['rouge-2'])\n",
    "print(\"[ROUGE L]\", results['rouge-l'])\n",
    "print(\"[BLEU]\", blue_score)\n",
    "\n",
    "for src, tgt, gen in zip(test_srcs, test_tgts, gens):\n",
    "\n",
    "    if 'ARTICLE=>' in gen:\n",
    "        gen = gen.split('ARTICLE=>')[1].strip()\n",
    "\n",
    "    # preprocess for better lexicon matching for bias analysis\n",
    "    src = preprocess_text(src)\n",
    "    tgt = preprocess_text(tgt)\n",
    "    gen = preprocess_text(gen)\n",
    "\n",
    "    gen_minus_gold_tokens = set(word_tokenize(gen)).difference(word_tokenize(tgt))\n",
    "\n",
    "    gen_v_score, gen_v_positive, gen_v_negative, _, \\\n",
    "    (gen_p_arousal, gen_n_arousal, _), (gen_positive, gen_negative, _) \\\n",
    "    = obtain_instance_bias_scores(gen_minus_gold_tokens, vad_dict)\n",
    "\n",
    "    test_gen_score_dict['v'] += gen_v_score\n",
    "    test_gen_score_dict['v_positive'] += gen_v_positive\n",
    "    test_gen_score_dict['v_negative'] += gen_v_negative\n",
    "\n",
    "    test_gen_score_dict['calibrated_p_arousal'] += gen_p_arousal\n",
    "    test_gen_score_dict['calibrated_n_arousal'] += gen_n_arousal\n",
    "\n",
    "    # gen_other_bias_dict = other_bias_lexicon_analysis(gen_minus_gold_tokens)\n",
    "    # for key in gen_other_bias_dict:\n",
    "    #     test_gen_score_dict[key] += gen_other_bias_dict[key]\n",
    "\n",
    "\n",
    "for dict_ in [test_gen_score_dict]:\n",
    "    for key, value in dict_.items():\n",
    "        val = value\n",
    "        print(\"[{}]: {:.2f} | {:.2f}\".format(key, val, val/cnt))\n",
    "print()\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb54ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
